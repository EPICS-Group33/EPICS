{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "iNwSajFw9n5d",
        "outputId": "5f952820-602d-46eb-8626-91b4e7a540a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.10/dist-packages (0.0.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install ucimlrepo\n",
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "ijjbQOpmHmGW"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# Fetch the CDC Diabetes health indicators data\n",
        "cdc_diabetes_health_indicators = fetch_ucirepo(id=891)\n",
        "\n",
        "# Data (as pandas dataframes)\n",
        "x = cdc_diabetes_health_indicators.data.features.iloc[:,1:-2]\n",
        "y = cdc_diabetes_health_indicators.data.targets"
      ],
      "metadata": {
        "id": "6yPsab79-Wsd"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle missing values by dropping rows (alternative approach)\n",
        "x_dropna = x.dropna()  # Drop rows with any missing values\n",
        "y_dropna = y.loc[x_dropna.index]  # Select corresponding target labels\n",
        "\n",
        "# Encode categorical features (if any)\n",
        "categorical_features = [i for i in range(len(x_dropna.columns)) if x_dropna.dtypes[i] == 'object']  # Assuming object dtype for categorical features\n",
        "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')  # One-hot encoding\n",
        "x_encoded = pd.concat([x_dropna, pd.DataFrame(encoder.fit_transform(x_dropna[categorical_features]))], axis=1)\n",
        "x_encoded.drop(categorical_features, axis=1, inplace=True)  # Remove original categorical features\n",
        "\n",
        "# Scale numerical features\n",
        "scaler = StandardScaler()\n",
        "x_scaled = scaler.fit_transform(x_encoded)\n",
        "\n",
        "# Train-Test Split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y_dropna, test_size=0.2, random_state=42)\n",
        "\n",
        "# Logistic Regression Model\n",
        "model = LogisticRegression()\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Make predictions on testing set\n",
        "y_pred = model.predict(x_test)"
      ],
      "metadata": {
        "id": "alfONuqD_Ay-",
        "outputId": "f05a0d0f-54aa-4472-9c88-ab9b778444bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-Score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jH9qEpVCzxd",
        "outputId": "9e3ad839-3d3b-44fa-91b7-ee36cb238420"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8638245033112583\n",
            "Precision: 0.522680412371134\n",
            "Recall: 0.14491925110761755\n",
            "F1-Score: 0.22692178583417258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data (replace with actual values based on feature descriptions)\n",
        "new_data = [[1,1,1,40,1,0,0,0,0,1,1,0,5,18,15,1,0,9]]  # Sample features for prediction\n",
        "\n",
        "# Scale the new data\n",
        "new_data_scaled = scaler.transform(new_data)\n",
        "\n",
        "# Make prediction on the new data\n",
        "prediction = model.predict(new_data_scaled)\n",
        "\n",
        "# Print the prediction result (0 for not diabetes, 1 for diabetes)\n",
        "print(prediction.tolist())\n"
      ],
      "metadata": {
        "id": "UqoYjlHUB9zi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c5d549b-6134-4bb2-aba5-9e63ad7fa175"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}